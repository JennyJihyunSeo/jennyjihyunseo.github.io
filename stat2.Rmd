---
pagetitle: "Stat2"
output:
  html_document:
    toc: true
    toc_depth: 5
    toc_float:
     collapsed: true
     smooth_scroll: false
---

<link rel="stylesheet" href="styles.css" type="text/css">
<link rel="stylesheet" href="site_libs/academicons-1.9.1/css/academicons.min.css"/>

<br><br><br>

---
title: "Statistics using R"
---

<br><br><br>

## 1. Hypothesis Testing with Two-Sample Proportion Test

![](https://img.shields.io/badge/Using-R-blue)


<br>

### 1. Figure

<p align="center">
<img src="images/Lecture1.png" style="width:80%; height:auto;" align="center">
</p>
<p align="center">
[Fig. Treatment Effects between New banner Ad and Old Banner Ad]
</p>


<br>

<br><br>

### 2. Goal

To test if the Click-Through-Rate (CTR) difference between Ad B (treatment group) and Ad A (Control group). 

<br>

### 3. Hypotheses

**Null Hypothesis (H₀):**
- The null hypothesis indicates Ad B is not effective than Ad A
- The null hypothesis indicates the CTR (Click through Rate) of Ad B is less than or equal to the CTR (Click through Rate) of Ad A
$$
H_0: p_B \leq p_A
$$

**Alternative Hypothesis (H₁):**
- The null hypothesis indicates Ad B is more effective than Ad A
- The null hypothesis indicates the CTR (Click through Rate) of Ad B is more than the CTR of Ad A 
$$
H_1: p_B > p_A
$$

<br>

### 4. Methodology & Summary

  + Two Sample proportion z-test was used: 
     + Ad A and Ad B each had 500 samples.
     + Success = clicking the ad (CTR).
     + CTR of Ad A = 3% CTR and Ad B = 5.6% CTR. 
     + Result: p-value = 0.0307 rejecting the null hypothesis.
     
  + Conclusion: At a 0.05 significance level, the p-value of 0.0307 indicates that the null hypothesis (Ad B is not more effective than Ad A) can be rejected. The p-value represents the probability of observing a result as extreme as, or more extreme than, the current outcome under the assumption that the null hypothesis is true. Since the p-value is less than the significance level, we have sufficient evidence to reject the null hypothesis, suggesting that Ad B is statistically significantly more effective than Ad A.


<br>

### 5. Code

```{r}
#Q1
### Set seed to ensure we consistently generate the same results
set.seed(1)

### Create two random samples of A and B with sample size 500 respectively 
### A and B are distributed binomial with sample means 0.03 and 0.05
### A and B follow binomial distributions while indicating 1 is success (clicking the Ad) and 0 is failure (not clicking the Ad)
nbin <- 500
A <- data.frame(CTR = rbinom(n = nbin, prob = 0.03, size = 1))
B <- data.frame(CTR = rbinom(n = nbin, prob = 0.05, size = 1))

### Sample counts, counting the success of clicking the Ad.
countA <- sum(A$CTR)
countB <- sum(B$CTR)

### Two-sample proportions z-test with one-sided test 
prop.test(x = c(countB, countA), 
          n = c(nbin, nbin), 
          alternative = "greater")

# Ad B is clicked 5% otherwise Ad A is clicked 3% on the time but this is very unlikely (only 3% based on the p-value) that 
# this outcome can be gained under the assumption that the null hypothesis is true. Therefore, we suspect that the null hypothesis is not true.
```

<br>

<br><br><br>

## 2. Hypothesis Testing with 10,000 Random Samples 

![](https://img.shields.io/badge/Using-R-blue)


<br>



<br><br><br>

### 1. Figure

<p align="center">
<img src="images/Lecture1.png" style="width:80%; height:auto;" align="center">
</p>
<p align="center">
[Fig. Treatment Effects between New banner Ad and Old Banner Ad]
</p>


<br>

<br><br>

### 2. Goal
To test if the mean Click-Through-Rate (CTR) between Ad A and Ad B is greater than 2.6%.

<br>

### 3. Hypotheses

**Null Hypothesis (H₀):**

The mean difference in CTR between Ad B and Ad A is **less than or equal to 2.6%**:

$$
H_0: \mu_B - \mu_A \leq 0.026
$$

**Alternative Hypothesis (H₁):**

The mean difference in CTR between Ad B and Ad A is **greater than 2.6%**:

$$
H_1: \mu_B - \mu_A > 0.026
$$

<br>

### 4. Methodology & Summary

  + Two Sample proportion z-test was used: 
     + 10,000 random samples of size 500 were drawn for both Ad A and Ad B, assuming both had a mean CTR of 4.3%, which indicates that those samples are simulated under the assumption that the null hypothesis is true as the mean of each distribution is the same as each other. 
     + The mean CTR difference was calculated.
     + If the mean difference exceeded 2.6%, the null hypothesis was rejected. 
     + Result: p-value = 0.0242 rejecting the null hypothesis.
     
  + Conclusion: At a 0.05 significance level, the p-value of 0.0242 indicates that the null hypothesis (The mean difference between the two Ads is less than or equal to 2.6%.) can be rejected. The p-value represents the probability of observing a difference as extreme as, or more extreme than, 2.6% under the assumption that the null hypothesis is true. The probability of observing this extreme value (the mean difference between the two Ads greater than 2.6%) is 2.4%. Since the p-value is less than the significance level, we have sufficient evidence to reject the null hypothesis, suggesting that Ad B is statistically significantly 2.6% more effective than Ad A.


<br>

### 5. Code

```{r}
### 10,000 random samples from binomial with mean 0.043, for both Ad A and AD B which fits the null hypothesis with Ad B not being more effective than Ad A
### 4.3% indicates the average CTR of A and B 
### The purpose for this sampling is to identify whether CTR for Ad B is 2.6% larger than Ad A even if we got random samples for binomial distribution with the same average mean for both Ad A and Ad B. 

set.seed(1)
### Create data frame for mean of samples 
hypothesis <- data.frame(matrix(0, nrow = 10000, ncol = 4))

### Name columns 
colnames(hypothesis) <- c('A', 'B', 'Dif', 'RejectH0')

for (x in 1:10000) {
  # The sample mean is the same as 4.3% (CTR = 4.3%)
  hypothesis$A[x] <- mean(rbinom(n = nbin, prob = 0.043, size = 1))
  hypothesis$B[x] <- mean(rbinom(n = nbin, prob = 0.043, size = 1))
  
  # The difference in CTR between A and B
  hypothesis$Dif[x] <- hypothesis$B[x] - hypothesis$A[x]
  
  # If the CTR of B is greater than 2.6% than A, we reject the null hypothesis.
  hypothesis$RejectH0[x] <- ifelse(hypothesis$B[x] - hypothesis$A[x] > 0.026, 1, 0)
}

# The summary table of the result for this hypothesis testing.
summary(hypothesis$RejectH0)
```

<br>

<br><br><br>

## 3. Random Sampling

![](https://img.shields.io/badge/Using-R-blue)


<br>



<br><br><br>

### 1. Figure

<p align="center">
<img src="images/RandomSampling.png" style="width:80%; height:auto;" align="center">
</p>
<p align="center">
[Fig. How Sample Mean Evolves as Sample Size Increases]
</p>


<br>

<br><br>

### 2. Goal

  + To demonstrate how the sample mean evolves as the sample size increases, and how the population variance affects the variability of sample means. 
     + The sample mean becomes closer to the true population mean as the sample size increases. 
     + The stability of sample means improves when sampling from populations with lower variance. 
     
<br>

### 3. Methodology

  1. Setup:
     + Two populations are sampled, both with a mean of 70 but with different variances. 
       + Population 1: Variance = 36 (Standard Deviation = 6)
       + Population 2: Variance = 9 (Standard Deviation = 3)
     + Sample sizes range from 1 to 100.  
   
  2. Process:
     + Random samples are drawn from each population for each sample size (1 to 100).
     + The sample means are calculated and stored for both populations.     
  
  3. Process:
     + The sample means are plotted against sample sizes to observe trends.
     + Red Line: Population with larger variance (36)
     + Blue Line: Population with smaller variance (9)
   
  4. Conclusion:
     + When the population variance is larger and sampling from this population, the sample means vary largely when the sample size is smaller. This variance is getting smaller when the sample size increases. In contrast, if the population variance is smaller and random samples from this population, there is less variability in the sample means compared to the first random sampling from the population with larger variance. The sample mean of the second population gets closer to the population mean which is 70 rapidly while showing greater stability even when the sample size is small. 
     

<br>

### 4. Code

```{r}
### Set seed to ensure we consistently generate the same results 
set.seed(1)

### Create data frame to store the means of the samples
sample_example <- data.frame(matrix(0, nrow = 100, ncol = 3))

### Name columns
colnames(sample_example) <- c('ssize', 'mean1', 'mean2')

# Create random samples from a normal distribution with mean = 70 but with different variance
# Sample sizes range from 1 to 100

for (x in 1:100) {
  # Generate random samples for two sets from the normal distribution with the same mean 70 and different variances. The first sample has 70 as mean and 36 as variance. The second sample has 70 as mean and 9 as variance. 
  sample_run1 <- data.frame(sample = rnorm(x, 70, 36))
  sample_run2 <- data.frame(sample = rnorm(x, 70, 9))
  
  # Store the sample size
  sample_example$ssize[x] <- x
  
  # Calculate the means of the samples and store them 
  sample_example$mean1[x] <- mean(sample_run1$sample)
  sample_example$mean2[x] <- mean(sample_run2$sample)
}

# View the results
head(sample_example)

# When the sample size is the same in each row, if the standard deviation is smaller, we could get more stable sample means closer to the population mean 70.
```
```{r}
### Plot X=Sample Size, Y = mean
library(ggplot2)
ggplot() + 
  geom_line(data=sample_example, aes(x=ssize,y=mean1), color="red")+ 
  geom_line(data=sample_example, aes(x=ssize,y=mean2), color="blue")+ 
  ggtitle("How sample mean evolves as sample size increases") +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(x='Sample Size',y='Sample Mean')
```
<br>

<br><br><br>

## 4. Multi-Armed Bandit

![](https://img.shields.io/badge/Using-R-blue)


<br>



<br><br><br>

### 1. Definition 

  + The Multi-Armed Bandit approach tests multiple levers (e.g., advertisements) to identify the best lever offering the highest compensation. In this case: 
     + 4 advertisements are tested to determine the one with the highest CTR (Click-Through Rate).
     + Fisher's exact test is used instead of the proportion test when sample sizes (exposures of advertisements) are low. 
     

<br>

<br><br>

### 2. Goal
To identify the advertisement with the highest CTR and evaluate whether any other advertisements can serve as suitable alternatives. 
     
<br>

### 3. Methodology

  1. Setup:
     + Four advertisements (Ad1, Ad2, Ad3, Ad4) are initialized with baseline CTRs:
       + Ad1: 2.5%, Ad2: 1%, Ad3: 0.5%, Ad4: 1.5%.
     + The best advertisement starts with the highest baseline CTR.
   
  2. Dynamic Sampling:
     + Advertisements are exposed probabilistically, with higher probabilities assigned to the current best-performing ad.
     + A random click (1 for success, 0 for failure) is generated based on the CTR of the selected ad.   
  
  3. Updating Beliefs:
     + Clicks and exposures are updated after each trial.
     + CTR for each advertisement is recalculated:
       - **CTR** (Click-Through Rate):  

$$
\text{CTR} = \frac{\text{Clicks}}{\text{Exposures}}
$$
     + CTR represents the ratio of the number of clicks to the number of times an advertisement was shown (exposures).
              
  4. Testing Significance: 
     + Once all advertisements have at least 10 exposures, Fisher's test is applied:
     + **Null Hypothesis (\(H_0\)):**  

     $$
H_0: \text{CTR}_{\text{Best}} \geq \text{CTR}_{\text{Alternative}}
     $$
     + **Alternative Hypothesis (\(H_1\)):**  
    
     $$
H_1: \text{CTR}_{\text{Best}} < \text{CTR}_{\text{Alternative}}
     $$
     + Advertisements with p-values < 0.05 are removed due to significant differences from the best ad.   
   
  5. Conclusion:
     + The process continues until only the best advertisement and its close alternatives (if any) remain. 
     + The first advertisement has the highest CTR and there are no suitable alternatives with similar CTR compared to the best choice. 
     

<br>

### 4. Code

```{r}
# Choose 4 advertisements 
N_ARMS = 4
# Identifier for each advertisement 
ARMS = c(1,2,3,4)
# Set the baseline CTR for each advertisement 
base_rates = c(.025,.01,.005,.015)
# Before the experiment, the first advertisement has the highest CTR
best = 1
# Initialize the number of clicks, the number of advertisement exposure, and CTR (the number of clicks / the total number of advertisement exposure)
clicks <-c(0,0,0,0)
draws <-c(0,0,0,0)
CTR <-c(0,0,0,0)

options(warn=-1)

set.seed(1)

while(N_ARMS>1){
  # Generate a random draw of ad from proportion .5 best, else other)
  # Set arm probabilities
  # Except for the best advertisement, 0.5 probabilities divided by remaining advertisements
  epsilon = .5/(N_ARMS-1)
  chosen_arm_p = c(0,0,0,0)
  for (i in 1:length(ARMS)) {
    chosen_arm_p[ARMS[i]]=epsilon
  }
  # Assign 0.5 exposure probability for the best advertisement
  chosen_arm_p[best]=.5
  # Choose the probability as the threshold to pull the arm
  choicep <- runif(1, min = 0, max = 1)
  choice=0
  # Choose the advertisement when the choice probability generated by uniform distribution is included in the cumulative range for each advertisement
  # If one of the advertisements is selected, choice == 0 is not satisfied and the for loop is ended. 
  for (i in 1:length(ARMS)) {
    if (choicep<=sum(chosen_arm_p[1:ARMS[i]]) & choice==0){choice=ARMS[i]}
  }
  # Generate click or not click using CTR for each advertisement set above
  # click has 1 (click) or 0 (not click) for one exposure 
  click <- rbinom(n=1,prob=base_rates[choice],size=1)
  # Update beliefs about frequency
  # Accumulate the number of clicks for each advertisement 
  clicks[choice] <- clicks[choice]+click
  # The number of exposure increments by 1 for every trial 
  draws[choice] <- draws[choice]+1
  # If the exposure is 0, the value is returned as 0 whereas CTR is calculated as clicks[choice] / draws [choice]
  CTR[choice] = ifelse(draws[choice]==0, 0, (clicks[choice]/draws[choice]))
  # Re-assign best 
  best=0
  # CTR object stores the CTR for each advertisement and find the best advertisement with the max CTR value
  for (i in 1:length(ARMS)) {
    if (CTR[ARMS[i]]==max(CTR) & best==0){best=ARMS[i]}
  }
  # Test for significant difference between the best advertisement and the rest of the options
  # Remove all for which p-value <0.05, indicating that there is significant difference between the best and other option
  # Only remove once each alternative has been drawn at least ten times 
  # prop.test inappropriate and gives error if samples are too small
  # The minimum exposure for each advertisement is greater than 10
  if (min(draws)>10) {
  keep = c()
  for (i in 1:length(ARMS)) {
    if (ARMS[i]!=best) {
      # The null hypothesis for the prop.test is CTR(best) is greater or than or equal to CTR(alternative) and the alternative hypothesis is CTR(best) is less than CTR(alternative). 
      # If the null hypothesis is rejected, that alternative should be removed because there is statistically significant difference between the two. However, in this example. prop.test cannot be used due to lower exposure. Chi-squared test may not be appropriate when numerator is zero or very low.
      # Fisher's test should be used 
    result<-fresult <- fisher.test(
  matrix(
    c(clicks[best], clicks[ARMS[i]], 
      draws[best] - clicks[best], draws[ARMS[i]] - clicks[ARMS[i]]),
    nrow = 2
  ),
  alternative = "greater"
)
    if (result$p.value>.05) {keep=c(keep,ARMS[i])}
    }
    if (ARMS[i]==best) {keep = c(keep,best)}
  }
  N_ARMS = length(keep)
  ARMS=keep
  }
}

ARMS  
```


```{r}
rbind(base_rates, CTR)
```

```{r}
draws
```

<br>

<br><br><br>

## 5. Instagram Ads A/B Testing (Disney)

![](https://img.shields.io/badge/Using-R-blue)


<br>



<br><br><br>

### 1. Figure

<p align="center">
<img src="images/Disney.png" style="width:80%; height:auto;" align="center">
</p>
<p align="center">
[Fig. Decide whether to continue on the Ad based on Incremental Conversion Rate]
</p>
     

<br>

<br><br>

### 2. Goal
To identify whether any treatment effect represented by Incremental Conversion Rate (ICR) is positive.
     
<br>

### 3. Hypotheses and Formula of ICR
+ The **Incremental Conversion Rate (ICR)** is defined as:
   - **ICR** (Incremental Conversion Rate):  

   $$
   \text{ICR} = \text{Conversion_Rate(Treatment)} - \text{Conversion_Rate(Control)}
   $$

+ **Treatment group**: Exposed to the advertisement.  
+ **Control group**: Not exposed to the advertisement.

+ **Null Hypothesis (\(H_0\)):**

   $$
   H_0: \text{ICR} \leq 0 \quad \text{(The incremental conversion rate is less than or equal to 0)}.
   $$

+ **Alternative Hypothesis (\(H_1\)):**

   $$
   H_1: \text{ICR} > 0 \quad \text{(The incremental conversion rate is greater than 0)}.
   $$




### 4. Conclusion:
+ The p-value obtained from this test allow us to reject the null hypothesis. This indicates that the conversion rate in the treatment group is statistically significantly greater than that in the control group.   


<br>

### 5. Code

```{r}
# Load the RData file
load("DisneyAB.Rdata") 
### tests
### Proportion test for ICR
# Sample is 10,000 people for treatment group and control group 
sample=10000
# 
prop.test(x=c(sum(DisneyAB$TreatConv),sum(DisneyAB$ControlConv)), n=c(sample,sample), alternative = "greater")
```

<br>

<br><br><br>

## 6. Instagram Ads ROI (Return On Investment) (Disney)

![](https://img.shields.io/badge/Using-R-blue)


<br>



<br><br><br>

### 1. Figure

<p align="center">
<img src="images/AloA.png" style="width:80%; height:auto;" align="center">
</p>
<p align="center">
[Fig. Calculate ROI to decide whether to continue on the Advertisement.]
</p>
     

<br>

<br><br>

### 2. Goal
To identify whether the conversion revenue is different between converted treatment and control group. In addition, Return On Investment (ROI) is calculated to decide whether to continue on the advertisement. 
     
<br>

### 3. Hypotheses and Formula of ROI:
+ **Null Hypothesis (\(H_0\)):**  

   $$
   H_0: \mu_{\text{Treatment}} = \mu_{\text{Control}}
   $$

+ **Alternative Hypothesis (\(H_1\)):**  

   $$
   H_1: \mu_{\text{Treatment}} \neq \mu_{\text{Control}}
   $$

+ The **ROI** is calculated as follows: Sample 10,000 people for treatment and control group. Total cost of experiment is \( 10,000 \times 0.2 = 20 \).

   $$
   \text{ROI} = \frac{\text{Revenue}_{\text{Treatment}} - \text{Revenue}_{\text{Control}} - \text{Cost}}{\text{Cost}}
   $$


### 4. Conclusion:
+ At 0.05 significance level, the null hypothesis cannot be rejected, indicating there is no statistically significant difference in conversion revenue between the converted control and treatment group exposed to Disney advertisement. Consequently, the experiment does not provide sufficient evidence to conclude that the Disney advertisement has a significant impact on the average conversion revenue among converted users.

+ The Disney advertisement generates 305.95 times the return on investment compared to the cost of running the advertisement, relative to the control group.


<br>

### 5. Code

```{r}
### Subset the data
DisTRev <- subset(DisneyAB$TreatRev, DisneyAB$TreatConv == 1)
DisCRev <- subset(DisneyAB$ControlRev, DisneyAB$ControlConv == 1)

### Test Welch Two Sample t-test under the assumption that the variances between the two differ
t.test(DisTRev, DisCRev, alternative = "two.sided", var.equal = FALSE)
```

```{r}
### ROI Disney 
(sum(DisTRev)-sum(DisCRev)-20)/20
```

<br>

<br><br><br>

## 7. Instagram Ads A/B Testing (Alo)

![](https://img.shields.io/badge/Using-R-blue)


<br>



<br><br><br>

### 1. Figure

<p align="center">
<img src="images/AloA.png" style="width:80%; height:auto;" align="center">
</p>
<p align="center">
[Fig. Decide whether to continue on the Ad based on Incremental Conversion Rate]
</p>
     

<br>

<br><br>

### 2. Goal
To identify whether any treatment effect represented by Incremental Conversion Rate (ICR) is positive.
     
<br>

### 3. Hypotheses and Formula of ICR

+ The **Incremental Conversion Rate (ICR)** is defined as:

   - **ICR** (Incremental Conversion Rate):  

     $$
     \text{ICR} = \text{Conversion\_Rate(Treatment)} - \text{Conversion\_Rate(Control)}
     $$

   - **Treatment group**: Exposed to the advertisement.  
   - **Control group**: Not exposed to the advertisement.

+ **Null Hypothesis (\(H_0\)):**  

   $$
   H_0: \text{ICR} \leq 0 \quad \text{(The incremental conversion rate is less than or equal to 0)}.
   $$

+ **Alternative Hypothesis (\(H_1\)):**  

   $$
   H_1: \text{ICR} > 0 \quad \text{(The incremental conversion rate is greater than 0)}.
   $$


### 4. Conclusion:
+ The p-value obtained from this test allow us to reject the null hypothesis. This indicates that the conversion rate in the treatment group is statistically significantly greater than that in the control group.   


<br>

### 5. Code

```{r}
load("AloAB.Rdata") 
### tests for another data
### Proportion test for ICR
### ICR = Conversion_Rate(Treatment) − Conversion_Rate(Control)
# Assign 10,000 units for both treatment and control groups 
sample=10000
prop.test(x=c(sum(AloAB$TreatConv),sum(AloAB$ControlConv)), n=c(sample,sample), alternative = "greater")
```


<br>

<br><br><br>

## 8. Instagram Ads ROI (Return On Investment) (Alo)

![](https://img.shields.io/badge/Using-R-blue)


<br>



<br><br><br>

### 1. Figure

<p align="center">
<img src="images/AloA.png" style="width:80%; height:auto;" align="center">
</p>
<p align="center">
[Fig. Calculate ROI to decide whether to continue on the Advertisement]
</p>
     

<br>

<br><br>

### 2. Goal
To identify whether the conversion revenue is different between converted treatment and control group. In addition, Return On Investment (ROI) is calculated to decide whether to continue on the advertisement. 
     
<br>

### 3. Hypotheses and Formula of ROI:

+ **Null Hypothesis (\(H_0\)):**  

   $$
   H_0: \mu_{\text{Treatment}} = \mu_{\text{Control}}
   $$

+ **Alternative Hypothesis (\(H_1\)):**  

   $$
   H_1: \mu_{\text{Treatment}} \neq \mu_{\text{Control}}
   $$

+ The **ROI** is calculated as follows:  
   Sample 10,000 people for the treatment and control groups.  
   Total cost of the experiment is \( 10,000 \times 0.2 = \$20 \).

   $$
   \text{ROI} = \frac{\text{Revenue}_{\text{Treatment}} - \text{Revenue}_{\text{Control}} - \text{Cost}}{\text{Cost}}
   $$
 

### 4. Conclusion:
+ At 0.05 significance level, the null hypothesis cannot be rejected, indicating there is no statistically significant difference in conversion revenue between the converted control and treatment group exposed to Alo advertisement. Consequently, the experiment does not provide sufficient evidence to conclude that the Alo advertisement has a significant impact on the average conversion revenue among converted users. 

+ In case of ROI of the Alo advertisement, the treatment group exposed to the advertisement 0.3655 times the return on investment compared to the cost of running the advertisement, relative to the control group. This indicates that the Alo advertisement is less effective to generate more revenue from the treatment group compared to the control group. 


<br>

### 5. Code

```{r}
AloTRev <- subset(AloAB$TreatRev, AloAB$TreatConv == 1)
AloCRev <- subset(AloAB$ControlRev, AloAB$ControlConv == 1)
t.test(AloTRev, AloCRev, alternative = "two.sided", var.equal = FALSE)
```

```{r}
(sum(AloTRev)-sum(AloCRev)-20)/20
```

<br>

<br><br><br>

## 9. Hypothesis Testing with Multiple Treatments

![](https://img.shields.io/badge/Using-R-blue)

<br>

<br><br><br>

### 1. Figure

<p align="center">
<img src="images/Nutrition.png" style="width:80%; height:auto;" align="center">
</p>
<p align="center">
[Fig. Do Nutrition Labels Encourage Healthier Eating?]
</p>
     

<br>

<br><br>

### 2. Objective
To determine if there is any difference in the average nutrition score of shopping baskets across different labeling treatments for an online grocer. The treatments include:
- **Star Nutrition Labels**
- **Letter Grade Nutrition Labels**
- **Warning Labels**
- **Control Group (No Labels)**

Dependent variable: Average nutrition score of the shopping basket.

<br>

### 3. Methodology

#### (a) Visualization
Using boxplots to compare the basket scores across treatments.

```{r}
getwd()
file_path <- "C:/Users/sjh50/OneDrive/문서/UC Davis/Paul/Github/Lecture2/Grocery.Rdata"
load("Grocery.Rdata")

library(DescTools)
library(ggplot2)
```

```{r}
summary(Grocery$BasketScore[Grocery$Condition=="Control"])
summary(Grocery$BasketScore[Grocery$Condition=="Star"])
summary(Grocery$BasketScore[Grocery$Condition=="Letter"])
summary(Grocery$BasketScore[Grocery$Condition=="Warn"])


### ggplot 
ggplot(Grocery, aes(x=Condition, y=BasketScore, fill=Condition)) + 
geom_boxplot()+
 theme(text = element_text(size = 20))
```

#### (b) ANOVA Test
To test for significant differences in means among treatments.

```{r}
### ANOVA test to identify whether there is significant difference in the mean among different treatments 
anova <-aov(BasketScore ~ Condition, data = Grocery)
summary(anova)
```

**Null Hypothesis (\(H_0\))**:
$$
H_0: \mu_{\text{Star}} = \mu_{\text{Letter}} = \mu_{\text{Warning}} = \mu_{\text{Control}}
$$

**Alternative Hypothesis (\(H_A\))**:
$$
H_A: \text{At least one group mean is different.}
$$

At 0.05 significance level, the null hypothesis can be rejected. It concludes that at least one treatment mean is different. In order to find which treatment differs, TukeyHSD is used for finding. 

#### (c) TukeyHSD Test
To identify which treatments differ.

```{r}
TukeyHSD(anova)
```
Interpretation: 
(1) Letter - Control: There is a statistically significant difference in basket score between Letter Nutrition Labels and no labels. If there are letter nutrition labels, it encourages customers to buy healthier groceries while increasing the basket scores by 3.18 units compared to the control group. 
(2) Star - Control: There is a statistically significant difference in basket score between Star Nutrition Labels and no labels (control). When Star Nutrition Labels are displayed, they encourage customers to buy healthier groceries, increasing the basket score by 2.18 units compared to the control group. 
(3) Warn - Control: There is a statistically significant difference in basket score between Warn Nutrition Labels and no labels. Warning Labels have the strongest effect, leading to a increase of 5.38 units in basket scores compared to the control group. 
(4) Warn - Letter: When comparing Warning Nutrition Labels and Letter Nutrition Labels, there is a statistically significant difference in basket scores. Warning Labels are more effective, increasing basket scores by 2.18 units compared to Letter Nutrition Labels.
(5) Warn - Star: When comparing Warning Nutrition Labels and Star Nutrition Labels, there is a statistically significant difference in basket scores. Warning Labels are more effective, increasing basket scores by 3.19 units compared to Star Nutrition Labels.
(6) Star - Letter: It is not statistically significant in basket scores between Star and Letter labels. 

#### (d) Regression Analysis

```{r}
### Regression
OLS <- lm(Grocery$BasketScore ~ Grocery$Condition)
summary(OLS)
```
At a 0.05 significance level, the overall model is statistically significant but R-squared is low. Only 2.3% of the variation in the dependent variable is explained by independent variables. 
In terms of coefficients of the independent variables, all coefficients are statistically significant at 0.05 significance level. The baseline Basket Score for the control group is 55.27 units, meaning that the average basket scores without labels is 55.27 units. In case of Warning Nutrition Labels, if there is one unit increase in the use of Warning Nutrition Labels, basket scores increase by 5.37 units on average.

<br>

### 4. Additional Analyses

#### (a) Dunnett's Test

Dunnett's Test is specifically designed to compare the control group with each of the treatment groups individually. 

```{r}
DunnettTest(x=Grocery$BasketScore, g=Grocery$Condition)
```
Interpretation:
All treatment groups increase the basket scores compared to the control group which means that all of them are effective to encourage people to buy healthier food. In case of Warning Nutrition Labels, it is the most effective labeling method compared to the other options by increasing 5.37 units of the basket scores. 

#### (b) Binary Analysis: Warning vs. Others

```{r}
# Make Warning Nutrition Labels as 1 and the other labels (Control, Letter, Star) as 0
Grocery$Warning <- 0
Grocery$Warning[Grocery$Condition == "Warn"] <- 1
```

```{r}
OLS2 <- lm(Grocery$BasketScore ~ Grocery$Warning)
summary(OLS2)
```
When there are not Warning Nutrition Labels, the average basket score is 57.06. If there is Warning Nutrition Labels, it increases the basket scores by 3.58 units. At 0.05 significance level, the coefficient of Warning Labels is statistically significant. The overall model is valid due to the p-value less than 0.05 significance level. 


Compare the mean difference between Warning Nutrition Labels and the other label options to identify any significant mean difference in Waring Nutrition Labels in the basket scores compared with the other options.

**Null Hypothesis (\(H_0\))**:
$$
H_0: \mu_{\text{Warning}} \leq \mu_{\text{Other}}
$$

**Alternative Hypothesis (\(H_A\))**:
$$
H_A: \mu_{\text{Warning}} > \mu_{\text{Other}}
$$
```{r}
t.test(Grocery$BasketScore[Grocery$Warning==1], Grocery$BasketScore[Grocery$Warning==0], alternative = "greater", var.equal = FALSE)
```
At 0.05 significance level, the null hypothesis can be rejected. There is a statistically significant mean difference in the basket scores between Warning Nutrition Labels and other Label options and the mean basket scores of Warning Nutrition Labels is greater than the other labels. 


### 5. Pairwise Comparisons

#### (a) Warning vs. Nutrition (Star + Letter)

```{r}
# Combine Letter and Star as Nutrition
Grocery$Condition2 <- Grocery$Condition
Grocery$Condition2[Grocery$Condition == "Letter" | Grocery$Condition == "Star"] <- "Nutrition"

t.test(Grocery$BasketScore[Grocery$Condition2 == "Warn"], 
       Grocery$BasketScore[Grocery$Condition2 == "Nutrition"], 
       alternative = "greater", 
       var.equal = FALSE)
```

**Null Hypothesis (\(H_0\))**:
$$
H_0: \mu_{\text{Warn}} \leq \mu_{\text{Nutrition}}
$$

**Alternative Hypothesis (\(H_A\))**:
$$
H_A: \mu_{\text{Warn}} > \mu_{\text{Nutrition}}
$$
At 0.05 significance level, the null hypothesis can be rejected. The mean basket scores of Warning Nutrition Labels are greater than the mean basket scores of combined Nutrition (Star and Letter) Labels. 

#### (b) Nutrition (Star + Letter) vs. Control

```{r}
t.test(Grocery$BasketScore[Grocery$Condition2=="Nutrition"], 
       Grocery$BasketScore[Grocery$Condition2=="Control"], 
       alternative = "greater", 
       var.equal = FALSE)
```

**Null Hypothesis (\(H_0\))**:
$$
H_0: \mu_{\text{Nutrition}} \leq \mu_{\text{Control}}
$$

**Alternative Hypothesis (\(H_A\))**:
$$
H_A: \mu_{\text{Nutrition}} > \mu_{\text{Control}}
$$
At 0.05 significance level, there is a statistically significant difference in the basket scores between Nutrition labels (Star and Letter) and Control groups. The null hypothesis can be rejected and the mean basket scores of Nutrition labels (Star and Letter) is greater than the mean basket scores of control groups. 

<br>

### 6. Conclusion

- Warning Labels are the most effective treatment, significantly increasing basket scores compared to all other treatments and the Control group.
- Nutrition Labels (Star + Letter) are also effective but less impactful than Warning Labels.
- Future recommendations could focus on optimizing the design and implementation of Warning Labels to maximize their impact on healthier grocery choices.


<br>

<br><br><br>

## 10. Parametric and Non-parametric Regression Analysis 

![](https://img.shields.io/badge/Using-R-blue)

<br>

<br><br><br>

### 1. Figure

<p align="center">
<img src="images/Regression.png" style="width:80%; height:auto;" align="center">
</p>
<p align="center">
[Fig. To Determine whether a Parametric or Non-parametric fit well with the data.]
</p>
     

<br>

<br><br>

### 2. Objective
To analyze the relationship between **Price** and **Unit Sales** using various regression approaches, including linear, non-linear, and non-parametric models.

<br>

### 2. Methodology

#### (a) Data Preparation

```{r}
load("Prices.Rdata")
```

#### (b) Visualizations

##### (i) Boxplot of Unit Sales by Price (Categorical)

```{r}
### Make a factor variable of prices to convert a continous variable into a categorical variable 
prices$PriceFactor <- as.factor(prices$Price)
### Figures using price as a factor
ggplot(prices, aes(x=PriceFactor, y=UnitSales)) + 
 geom_boxplot()
```

##### (ii) Scatterplot of Unit Sales vs. Price (Continuous)

Linear Trend:
```{r}
ggplot(prices, aes(x=Price, y=UnitSales)) + 
 geom_point() +
 geom_smooth(method=lm)
```
Non-linear Trend (Loess):
```{r}
ggplot(prices, aes(x=Price, y=UnitSales)) + 
 geom_point() +
 geom_smooth(method = "loess")
```

<br>

#### (c) Regression Models

##### (i) Linear Regression (Price as Continuous)

```{r}
### Simple Regression Models
 OLS1 <- lm(prices$UnitSales ~ prices$Price)
 summary(OLS1)
```
Interpretation: The above linear relationship while treating Price as a continuous variable. The Price coefficient is statistically significant at 0.05 significance level. When the Price increases by 1 unit, the Unit sales decreases by 557.408 units. 

##### (ii) Linear Regression (Price as Categorical)

```{r}
OLS2 <- lm(prices$UnitSales ~ prices$PriceFactor)
summary(OLS2)
```
Interpretation: Compared to the linear regression model with the same coefficient slope making the linearly decreasing regression model, when making Price variable as a categorical variable, the coefficient variables vary depending on different price factors, indicating the relationship between Unit sales and Price factors is non-linear. 

##### (iii) Polynomial Regression

```{r}
# Add higher-order terms for polynomial regression
prices$PriceSq <- prices$Price^2
prices$PriceCu <- prices$Price^3

OLS3 <- lm(prices$UnitSales ~ prices$Price + prices$PriceSq + prices$PriceCu)
summary(OLS3)
```

##### (iv) Log-Linear Regression

```{r}
prices$LnPrice <- log(prices$Price)
OLS4 <- lm(prices$UnitSales ~ prices$LnPrice)
summary(OLS4)
```

##### (v) Exponential Regression

```{r}
prices$ExpPrice <- exp(prices$Price)
OLS5 <- lm(prices$UnitSales ~ prices$ExpPrice)
summary(OLS5)
```

### 3. Results Comparison

- **Polynomial Regression (OLS3)**: Captures non-linear patterns with significant coefficients for higher-order terms.
- **Log-Linear Regression (OLS4)**: Provides a logarithmic fit, indicating percentage changes in Unit Sales relative to Price changes.
- **Exponential Regression (OLS5)**: Models rapid increases or decreases in Unit Sales.
- **Non-Parametric (Price as Categorical)**: Achieves the highest Adjusted R-squared value (0.7791) and the lowest residual standard error. However, non-parametric models have limited scalability outside experimental price points.


### 4. Conclusion
Among the models, treating Price as a categorical variable yielded the best fit (highest Adjusted R-squared). However, for prediction purposes, polynomial and log-linear regressions are more scalable and practical for prices beyond the experimental range.

<br>

<br><br><br>

## 11. Savings Analysis 

![](https://img.shields.io/badge/Using-R-blue)

<br>

### 1. Objective
To analyze the impact of treatment on deposit amounts across different income groups and age categories using t-tests and regression models. The analysis also explores conditional average treatment effects (CATEs) to identify individual-level treatment heterogeneity.

<br>

### 2. Methodology

#### (a) Visualizations

##### (i) Deposits by Age and Treatment Group

```{r}
load("Savings.Rdata")
```

```{r}
ggplot(Savings, aes(x=Age, y=Deposits, color=TreatGroup)) + 
  geom_point() +
  geom_smooth(method=lm, aes(group=TreatGroup))
```
##### (ii) Deposits by Income and Treatment Group

```{r}
ggplot(Savings, aes(x=Income, y=Deposits, color=TreatGroup)) + 
  geom_point() +
  geom_smooth(method=lm, aes(group=TreatGroup))
```

#### (b) Group Comparisons Using t-tests

##### (i) Create Income Groups and Age Dummies

**Null Hypothesis (\(H_0\))**:

$$
H_0: \mu_{\text{Treatment}} \leq \mu_{\text{Control}}
$$

**Alternative Hypothesis (\(H_A\))**:

$$
H_A: \mu_{\text{Treatment}} > \mu_{\text{Control}}
$$

```{r}
### t-tests by group
### Income group and age dummies
Savings$Age35 <- ifelse(Savings$Age>=35, 1, 0)
Savings$IncGrp <- "<$50K"
Savings$IncGrp <- ifelse(Savings$Income>=50000, "$50-100K", Savings$IncGrp)
Savings$IncGrp <- ifelse(Savings$Income>100000, ">$100K", Savings$IncGrp)

### t-tests
INC1t <- subset(Savings$Deposits, Savings$TreatGroup == 1 &     Savings$IncGrp=="<$50K")

INC1c <- subset(Savings$Deposits, Savings$TreatGroup == 0 &  Savings$IncGrp=="<$50K")

INC2t <- subset(Savings$Deposits, Savings$TreatGroup == 1 & Savings$IncGrp=="$50-100K")

INC2c <- subset(Savings$Deposits, Savings$TreatGroup == 0 & Savings$IncGrp=="$50-100K")

INC3t <- subset(Savings$Deposits, Savings$TreatGroup == 1 & Savings$IncGrp==">$100K")

INC3c <- subset(Savings$Deposits, Savings$TreatGroup == 0 & Savings$IncGrp==">$100K")

INCt <- subset(Savings$Deposits, Savings$TreatGroup == 1)
INCc <- subset(Savings$Deposits, Savings$TreatGroup == 0)

### Entire population
t.test(INCt, INCc, alternative = "greater", var.equal = FALSE)
```

Compare the deposit amounts between control group and treatment group to identify if there is any difference in mean deposit amounts between the two groups. At 0.05 significance level, the null hypothesis can be rejected and the mean deposit amount of the treatment group is greater than the mean deposit amount of the control group. 

##### (ii) Perform t-tests for Each Income Group

**Null Hypothesis (\(H_0\))**:
$$
H_0: \mu_{\text{Treatment, Income Group 1}} \leq \mu_{\text{Control, Income Group 1}}
$$

**Alternative Hypothesis (\(H_A\))**:
$$
H_A: \mu_{\text{Treatment, Income Group 1}} > \mu_{\text{Control, Income Group 1}}
$$
```{r}
### Income group 1 (<$50K)
t.test(INC1t, INC1c, alternative = "greater", var.equal = FALSE)
```
In the income group 1 (<$50K), the null hypothesis can be rejected at 0.05 significance level, the mean deposit amount of the treatment group in the income group 1 is greater than the mean deposit amount of the control group in the income group 1. 

**Null Hypothesis (\(H_0\))**:
$$
H_0: \mu_{\text{Treatment, Income Group 2}} \leq \mu_{\text{Control, Income Group 2}}
$$

**Alternative Hypothesis (\(H_A\))**:
$$
H_A: \mu_{\text{Treatment, Income Group 2}} > \mu_{\text{Control, Income Group 2}}
$$
```{r}
### Income group 2 ($50-100K)
t.test(INC2t, INC2c, alternative = "greater", var.equal = FALSE)
```
In the income group 2 ($50K-$100K), the null hypothesis can be rejected at 0.05 significance level, the mean deposit amount of the treatment group in the income group 2 is greater than the mean deposit amount of the control group in the income group 2. 

**Null Hypothesis (\(H_0\))**:
$$
H_0: \mu_{\text{Treatment, Income Group 3}} \leq \mu_{\text{Control, Income Group 3}}
$$
**Alternative Hypothesis (\(H_A\))**:

$$
H_A: \mu_{\text{Treatment, Income Group 3}} > \mu_{\text{Control, Income Group 3}}
$$
```{r}
### Income group 3 (>$100K)
t.test(INC3t, INC3c, alternative = "greater", var.equal = FALSE)
```
In the income group 3 (>$100K), the null hypothesis can be rejected at 0.05 significance level, the mean deposit amount of the treatment group in the income group 3 is greater than the mean deposit amount of the control group in the income group 3. 

<br>

### 3. Regression Analysis

#### (a) Model 1: Income Group Treatment Effects

```{r}
### A regression approach
### Create Variables
Savings$INC1<- ifelse(Savings$IncGrp=="<$50K",1,0)
Savings$INC2 <- ifelse(Savings$IncGrp=="$50-100K",1,0)
Savings$INC3 <- ifelse(Savings$IncGrp==">$100K",1,0)
Savings$TreatInc1 <- Savings$TreatGroup * Savings$INC1
Savings$TreatInc2 <- Savings$TreatGroup * Savings$INC2
Savings$TreatInc3 <- Savings$TreatGroup * Savings$INC3
### First Model
OLS<-lm(Savings$Deposits ~ Savings$TreatInc1 + Savings$TreatInc2 + Savings$TreatInc3 + Savings$INC1 + Savings$INC2 + Savings$INC3)
summary(OLS)
```
**Interpretation**:
- The intercept represents deposits for the control group in Income Group 3 (>$100K): 2064.56 units.
- **Treatment Effects**:
  - Income Group 1: +546.43 units (statistically significant).
  - Income Group 2: +587.95 units (statistically significant).
  - Income Group 3: +150.84 units (not statistically significant).
- Income groups except for Income group 3 has the lower savings amount compared to the Income group 3.
- The treatment is the difference in the savings amount between the control group and the treatment group for each income group. 

#### (b) Model 2: Interaction of Treatment and Income Groups

```{r}
OLS <- lm(Savings$Deposits ~ Savings$TreatGroup * Savings$IncGrp)
summary(OLS)
```
**Interpretation**: In the first regression model, it represents the treatment effect for each income group. The first regression shows different income levels affect the amount of deposits without any treatment effect. However, the most important thing to discuss is that it represents the treatment effect for each income group. Therefore, this regression model shows the treatment effect for each income level comparing with the control group for each income group. In contrast, the second regression model shows the baseline treatment effect of the income group 2 ($50-100K) which allows us to compare the treatment effect among different income levels. First, the income group 2 received the treatment effect increases deposit amounts by 587.95 units on average when comparing the income group 2 within the control group. The income group 1 received the treatment effect saved 41.52 units less than the income group 2 received the treatment effect. However, this estimate is not statistically significant, meaning that this difference is not a meaningful difference but just random variation. However, the income group 3 in the treatment effect saved 437.46 units less than the income 2 group under the treatment effect and this estimate is statistically significant,concluding that the treatment effect differs between these groups. 

#### (c) Model 3: Including Age Interactions

```{r}
### Third Model, with Age
OLS<-lm(Savings$Deposits ~ Savings$TreatGroup*Savings$IncGrp + Savings$TreatGroup*Savings$Age35)
summary(OLS)
```
**Interpretation**: Here in this regression model, Age and income are covariates to estimate CATEs (Conditional Average Treatment effects) which can estimate an individual's heterogeneous treatment effect. Age is a categorical variable with two different value, one of which is younger than 35 (<35) and the other one is older than or equal to 35 (>=35). Intercept 803.44 units represents people's average saving amounts in the control group under 35 (<35) within the income group 2 ($50-100K). The treatment group effect is 352.64 units, indicating that people received treatment effect who are younger than 35 within the income group 2 saved more deposits (treatment effect) on average compared to the control group. We can answer the following questions by combining the effects of covariates such as age and income and their corresponding interaction terms with the treatment group and calculate CATE (Conditional Average Treatment Effect).

(1) What would the treatment effect be for some of age 30 with income of $40K?
The treatment effect is 38.99 units less than the control group with the same age and within the same income group , which is people younger than 30 within the income group 1 in the control group, which is 803.44 - 206.15 =  597.29 units. In conclusion, the treatment effect is 558.30 units.
(2) What would the treatment effect be for some of age 30 with income of $75K?
The treatment effect is 325.64 units greater than the control group with the same age and within the same income group, which is people younger than 30 within income group2 in the control group, which is 803.44. In conclusion, the treatment effect is 1129.08 units. 

#### (d) Model 4: Continuous Income and Age

```{r}
### Fourth model, with continuous interactions
# Appropriate if the treatment effect relationship is linear
OLS<-lm(Savings$Deposits ~ Savings$TreatGroup*Savings$Income + Savings$TreatGroup*Savings$Age)
summary(OLS)
```

**Interpretation**: In this regression model, covariates such as income and age are both treated an continuous. In case of the intercept, it represents people in the control group when their age and income are both zero saved -1026 units on average but it is not realistic because in the real world, age and income cannot be zero. When people in the control group with their age and income being zero are treated, their savings increases by 367 units on average. When income increases by 1 unit in the control group, the savings increases by 0.007807 units on average. Similarly, if age increases by 1 unit, the savings increases by 48.47 units on average. When income increases by 1 unit , the treatment effect decreases by 0.004383 units on average whereas when age increases by 1 unit, the treatment effect increases by 8.963 units on average.


### 4. Conclusion
- The first model focuses on treatment effects for each income group, showing significant increases in deposits for Income Groups 1 and 2.
- The second model emphasizes comparisons between groups, revealing significant differences between Income Groups 3 and 2 under treatment.
- The inclusion of age in the third and fourth models highlights the role of individual-level covariates in explaining treatment heterogeneity.
- Continuous interaction models provide nuanced insights but require careful interpretation due to extrapolation limitations.




